{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcionalidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo YOLO11s fine-tuned\n",
    "model = YOLO('C:\\\\Users\\\\alvar\\\\Desktop\\\\Proyecto G3\\\\ProyectoGrupal-G3-UEM\\\\modelos\\\\best.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cantidad de clientes por zona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordenadas: (199, 115)\n",
      "Coordenadas: (424, 285)\n"
     ]
    }
   ],
   "source": [
    "# Funcion para determinar coordenadas de objetos en videos\n",
    "import cv2\n",
    "\n",
    "# Función de callback para obtener coordenadas al hacer clic\n",
    "def obtener_coordenadas(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:  # Solo muestra al hacer clic izquierdo\n",
    "        print(f'Coordenadas: ({x}, {y})')\n",
    "\n",
    "# Capturar un frame del video\n",
    "cap = cv2.VideoCapture('C:\\\\Users\\\\alvar\\\\Desktop\\\\Proyecto G3\\\\ProyectoGrupal-G3-UEM\\\\grabaciones\\\\grabacion_2025-02-21_19-42-20.mp4')\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if ret:\n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.setMouseCallback('Frame', obtener_coordenadas)  # Asigna la función al frame\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No se pudo leer el frame del video.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular la distancia entre un punto (px, py) y una línea definida por dos puntos (x1, y1) y (x2, y2)\n",
    "def distancia_punto_linea(px, py, x1, y1, x2, y2):\n",
    "    return abs((y2 - y1) * px - (x2 - x1) * py + x2 * y1 - y2 * x1) / np.sqrt((y2 - y1)**2 + (x2 - x1)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las coordenadas de la línea del mostrador (inicio y fin)\n",
    "x1_mostrador, y1_mostrador = 199, 115\n",
    "x2_mostrador, y2_mostrador = 424, 285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para contar los clientes cerca de la línea del mostrador\n",
    "def contar_clientes_linea(detecciones, x1_mostrador, y1_mostrador, x2_mostrador, y2_mostrador):\n",
    "    count = 0\n",
    "    clientes_detectados = []  # Lista para almacenar las coordenadas de los clientes detectados\n",
    "    for deteccion in detecciones:\n",
    "        bbox = deteccion.xywh[0]\n",
    "        x, y = bbox[0].item(), bbox[1].item()  # Centro en formato xywh\n",
    "        clase = int(deteccion.cls[0].item())\n",
    "\n",
    "        if clase == 1:\n",
    "            distancia = distancia_punto_linea(x, y, x1_mostrador, y1_mostrador, x2_mostrador, y2_mostrador)\n",
    "            if distancia < 30:  # Umbral para considerar que está en la zona del mostrador\n",
    "                count += 1\n",
    "                clientes_detectados.append((x, y))  # Guardar la coordenada de los clientes\n",
    "\n",
    "    return count, clientes_detectados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer video\n",
    "import cv2\n",
    "video = cv2.VideoCapture(\"C:\\\\Users\\\\alvar\\\\Desktop\\\\Proyecto G3\\\\ProyectoGrupal-G3-UEM\\\\grabaciones\\\\grabacion_2025-02-21_19-42-20.mp4\")\n",
    "\n",
    "# Lista para almacenar los resultados\n",
    "resultados = []\n",
    "\n",
    "# Extraer la fecha y hora inicial desde el nombre del archivo\n",
    "nombre_video = \"grabacion_2025-02-21_19-42-20.mp4\"\n",
    "fecha_hora_inicial_str = nombre_video.split('_')[1] + \" \" + nombre_video.split('_')[2].replace('.mp4', '')\n",
    "fecha_hora_inicial = datetime.strptime(fecha_hora_inicial_str, \"%Y-%m-%d %H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 clientes, 2 mostradors, 350.2ms\n",
      "Speed: 8.9ms preprocess, 350.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 2 mostradors, 303.3ms\n",
      "Speed: 2.1ms preprocess, 303.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 2 mostradors, 325.0ms\n",
      "Speed: 2.2ms preprocess, 325.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 323.9ms\n",
      "Speed: 2.6ms preprocess, 323.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 283.2ms\n",
      "Speed: 3.4ms preprocess, 283.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 343.0ms\n",
      "Speed: 2.4ms preprocess, 343.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 477.1ms\n",
      "Speed: 2.6ms preprocess, 477.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 368.3ms\n",
      "Speed: 3.2ms preprocess, 368.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 316.4ms\n",
      "Speed: 3.1ms preprocess, 316.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 291.0ms\n",
      "Speed: 3.0ms preprocess, 291.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 337.8ms\n",
      "Speed: 2.2ms preprocess, 337.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 375.0ms\n",
      "Speed: 2.5ms preprocess, 375.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 260.8ms\n",
      "Speed: 2.1ms preprocess, 260.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 349.6ms\n",
      "Speed: 2.5ms preprocess, 349.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 366.2ms\n",
      "Speed: 5.0ms preprocess, 366.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 279.7ms\n",
      "Speed: 2.3ms preprocess, 279.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 315.3ms\n",
      "Speed: 2.3ms preprocess, 315.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 335.5ms\n",
      "Speed: 2.8ms preprocess, 335.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 342.8ms\n",
      "Speed: 2.2ms preprocess, 342.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 336.8ms\n",
      "Speed: 4.3ms preprocess, 336.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 416.1ms\n",
      "Speed: 2.9ms preprocess, 416.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 353.5ms\n",
      "Speed: 2.5ms preprocess, 353.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 272.8ms\n",
      "Speed: 4.0ms preprocess, 272.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 empleado, 1 mostrador, 312.2ms\n",
      "Speed: 2.3ms preprocess, 312.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 295.4ms\n",
      "Speed: 2.2ms preprocess, 295.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 280.9ms\n",
      "Speed: 2.6ms preprocess, 280.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 310.8ms\n",
      "Speed: 2.0ms preprocess, 310.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 260.0ms\n",
      "Speed: 2.5ms preprocess, 260.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 empleado, 3 mostradors, 288.0ms\n",
      "Speed: 2.3ms preprocess, 288.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 empleado, 2 mostradors, 295.7ms\n",
      "Speed: 2.4ms preprocess, 295.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 empleado, 2 mostradors, 274.7ms\n",
      "Speed: 2.2ms preprocess, 274.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 empleado, 2 mostradors, 287.3ms\n",
      "Speed: 2.1ms preprocess, 287.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 empleado, 2 mostradors, 248.5ms\n",
      "Speed: 2.3ms preprocess, 248.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 2 mostradors, 257.0ms\n",
      "Speed: 2.0ms preprocess, 257.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 247.5ms\n",
      "Speed: 2.0ms preprocess, 247.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 2 mostradors, 289.4ms\n",
      "Speed: 2.8ms preprocess, 289.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 272.2ms\n",
      "Speed: 2.0ms preprocess, 272.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 269.8ms\n",
      "Speed: 2.8ms preprocess, 269.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 1 mostrador, 272.2ms\n",
      "Speed: 2.1ms preprocess, 272.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 1 mostrador, 256.7ms\n",
      "Speed: 2.4ms preprocess, 256.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 1 mostrador, 284.4ms\n",
      "Speed: 2.1ms preprocess, 284.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 273.9ms\n",
      "Speed: 2.1ms preprocess, 273.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 271.3ms\n",
      "Speed: 2.2ms preprocess, 271.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 264.5ms\n",
      "Speed: 2.1ms preprocess, 264.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 262.4ms\n",
      "Speed: 2.0ms preprocess, 262.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 mostrador, 262.4ms\n",
      "Speed: 2.6ms preprocess, 262.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 mostrador, 274.0ms\n",
      "Speed: 2.1ms preprocess, 274.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 mostrador, 276.9ms\n",
      "Speed: 2.1ms preprocess, 276.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 mostrador, 255.9ms\n",
      "Speed: 2.4ms preprocess, 255.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 252.8ms\n",
      "Speed: 2.1ms preprocess, 252.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 257.5ms\n",
      "Speed: 2.0ms preprocess, 257.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 267.1ms\n",
      "Speed: 2.2ms preprocess, 267.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 282.6ms\n",
      "Speed: 2.2ms preprocess, 282.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 1 empleado, 1 mostrador, 253.9ms\n",
      "Speed: 1.9ms preprocess, 253.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 1 empleado, 1 mostrador, 251.5ms\n",
      "Speed: 2.0ms preprocess, 251.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 mostrador, 257.1ms\n",
      "Speed: 2.7ms preprocess, 257.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 mostrador, 249.5ms\n",
      "Speed: 2.0ms preprocess, 249.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 mostrador, 249.9ms\n",
      "Speed: 1.9ms preprocess, 249.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 1 mostrador, 263.9ms\n",
      "Speed: 2.6ms preprocess, 263.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 mostrador, 258.0ms\n",
      "Speed: 2.2ms preprocess, 258.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 mostrador, 275.5ms\n",
      "Speed: 2.1ms preprocess, 275.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 empleado, 1 mostrador, 271.6ms\n",
      "Speed: 2.2ms preprocess, 271.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 empleado, 1 mostrador, 266.9ms\n",
      "Speed: 2.2ms preprocess, 266.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 mostrador, 251.0ms\n",
      "Speed: 2.0ms preprocess, 251.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 3 mostradors, 268.8ms\n",
      "Speed: 2.0ms preprocess, 268.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 2 mostradors, 289.0ms\n",
      "Speed: 2.1ms preprocess, 289.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 2 mostradors, 264.8ms\n",
      "Speed: 2.0ms preprocess, 264.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 2 mostradors, 258.3ms\n",
      "Speed: 2.1ms preprocess, 258.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 2 mostradors, 248.0ms\n",
      "Speed: 2.6ms preprocess, 248.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 3 mostradors, 250.1ms\n",
      "Speed: 1.9ms preprocess, 250.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 3 mostradors, 257.2ms\n",
      "Speed: 2.1ms preprocess, 257.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 3 mostradors, 276.9ms\n",
      "Speed: 2.1ms preprocess, 276.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 3 mostradors, 275.7ms\n",
      "Speed: 1.9ms preprocess, 275.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 clientes, 2 mostradors, 269.7ms\n",
      "Speed: 2.5ms preprocess, 269.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 2 mostradors, 245.6ms\n",
      "Speed: 2.5ms preprocess, 245.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 255.4ms\n",
      "Speed: 2.0ms preprocess, 255.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 255.1ms\n",
      "Speed: 2.0ms preprocess, 255.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 262.0ms\n",
      "Speed: 2.5ms preprocess, 262.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 2 mostradors, 265.7ms\n",
      "Speed: 2.0ms preprocess, 265.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 260.9ms\n",
      "Speed: 1.8ms preprocess, 260.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 288.0ms\n",
      "Speed: 2.7ms preprocess, 288.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 251.7ms\n",
      "Speed: 2.2ms preprocess, 251.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 272.8ms\n",
      "Speed: 2.0ms preprocess, 272.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 mostrador, 379.8ms\n",
      "Speed: 2.0ms preprocess, 379.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 2 mostradors, 270.4ms\n",
      "Speed: 2.1ms preprocess, 270.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 285.1ms\n",
      "Speed: 2.7ms preprocess, 285.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 282.4ms\n",
      "Speed: 2.0ms preprocess, 282.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 273.7ms\n",
      "Speed: 3.0ms preprocess, 273.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 clientes, 1 empleado, 255.7ms\n",
      "Speed: 2.1ms preprocess, 255.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 258.8ms\n",
      "Speed: 2.1ms preprocess, 258.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 262.8ms\n",
      "Speed: 2.1ms preprocess, 262.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 259.0ms\n",
      "Speed: 2.2ms preprocess, 259.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 284.9ms\n",
      "Speed: 2.1ms preprocess, 284.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 257.6ms\n",
      "Speed: 2.0ms preprocess, 257.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 287.5ms\n",
      "Speed: 2.6ms preprocess, 287.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 256.4ms\n",
      "Speed: 2.4ms preprocess, 256.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 277.2ms\n",
      "Speed: 2.4ms preprocess, 277.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 276.9ms\n",
      "Speed: 2.2ms preprocess, 276.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 1 mostrador, 245.0ms\n",
      "Speed: 2.1ms preprocess, 245.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 1 mostrador, 251.1ms\n",
      "Speed: 2.4ms preprocess, 251.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 263.5ms\n",
      "Speed: 2.1ms preprocess, 263.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 1 mostrador, 287.2ms\n",
      "Speed: 4.8ms preprocess, 287.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 1 mostrador, 237.9ms\n",
      "Speed: 2.0ms preprocess, 237.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 249.4ms\n",
      "Speed: 2.0ms preprocess, 249.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 1 empleado, 1 mostrador, 256.1ms\n",
      "Speed: 3.0ms preprocess, 256.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 1 empleado, 2 mostradors, 249.9ms\n",
      "Speed: 2.0ms preprocess, 249.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 1 empleado, 2 mostradors, 253.3ms\n",
      "Speed: 2.2ms preprocess, 253.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 2 mostradors, 276.1ms\n",
      "Speed: 1.9ms preprocess, 276.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 295.2ms\n",
      "Speed: 2.0ms preprocess, 295.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 3 mostradors, 256.6ms\n",
      "Speed: 2.3ms preprocess, 256.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 2 mostradors, 249.8ms\n",
      "Speed: 1.9ms preprocess, 249.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 2 mostradors, 261.6ms\n",
      "Speed: 2.2ms preprocess, 261.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 2 mostradors, 261.3ms\n",
      "Speed: 2.4ms preprocess, 261.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 2 mostradors, 315.5ms\n",
      "Speed: 2.4ms preprocess, 315.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 2 mostradors, 318.8ms\n",
      "Speed: 2.4ms preprocess, 318.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 1 mostrador, 399.8ms\n",
      "Speed: 2.3ms preprocess, 399.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 1 mostrador, 256.3ms\n",
      "Speed: 1.9ms preprocess, 256.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 1 mostrador, 327.6ms\n",
      "Speed: 2.0ms preprocess, 327.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# crea un csv con la cantidad de clientes cerca de mostrador detectados\n",
    "\n",
    "# Procesar cada fotograma\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Obtener el número de fotograma y calcular el tiempo en segundos\n",
    "    frame_number = int(video.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    segundos_transcurridos = frame_number / fps\n",
    "\n",
    "    # Calcular la nueva fecha y hora\n",
    "    nueva_fecha_hora = fecha_hora_inicial + timedelta(seconds=segundos_transcurridos)\n",
    "    fecha_hora_exacta = nueva_fecha_hora.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Realizar la detección de objetos (clientes y empleados)\n",
    "    resultados_deteccion = model(frame)\n",
    "\n",
    "    # Extraer las detecciones\n",
    "    detecciones = resultados_deteccion[0].boxes if resultados_deteccion else []\n",
    "\n",
    "    # Contar clientes cerca del mostrador y obtener sus coordenadas\n",
    "    clientes_mostrador, clientes_detectados = contar_clientes_linea(detecciones, x1_mostrador, y1_mostrador, x2_mostrador, y2_mostrador)\n",
    "\n",
    "    # Guardar la información del primer cliente detectado (si hay alguno)\n",
    "    if clientes_detectados:\n",
    "        x_cliente, y_cliente = clientes_detectados[0]  # Tomar la primera detección\n",
    "\n",
    "        # Guardar la detección en la lista\n",
    "        resultados.append([fecha_hora_exacta, clientes_mostrador, x_cliente, y_cliente])\n",
    "\n",
    "# Guardar los resultados en un CSV\n",
    "df = pd.DataFrame(resultados, columns=['Fecha Hora y Segundo', 'Clientes Cerca del Mostrador', 'X Cliente', 'Y Cliente'])\n",
    "df.to_csv('resultados_deteccion_mostrador_con_ubicaciones.csv', index=False)\n",
    "\n",
    "# Liberar el video y cerrar ventanas\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 clientes, 2 mostradors, 351.3ms\n",
      "Speed: 13.4ms preprocess, 351.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 2 mostradors, 311.6ms\n",
      "Speed: 2.6ms preprocess, 311.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 2 mostradors, 377.6ms\n",
      "Speed: 3.4ms preprocess, 377.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 390.8ms\n",
      "Speed: 2.5ms preprocess, 390.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 373.2ms\n",
      "Speed: 2.6ms preprocess, 373.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 444.7ms\n",
      "Speed: 2.3ms preprocess, 444.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 307.7ms\n",
      "Speed: 2.4ms preprocess, 307.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 340.3ms\n",
      "Speed: 2.4ms preprocess, 340.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 440.0ms\n",
      "Speed: 4.8ms preprocess, 440.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 355.5ms\n",
      "Speed: 3.1ms preprocess, 355.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 316.2ms\n",
      "Speed: 3.3ms preprocess, 316.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 314.1ms\n",
      "Speed: 2.4ms preprocess, 314.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 298.0ms\n",
      "Speed: 2.7ms preprocess, 298.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 377.9ms\n",
      "Speed: 10.3ms preprocess, 377.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 419.1ms\n",
      "Speed: 21.4ms preprocess, 419.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 348.4ms\n",
      "Speed: 14.2ms preprocess, 348.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 305.0ms\n",
      "Speed: 2.2ms preprocess, 305.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 327.3ms\n",
      "Speed: 2.1ms preprocess, 327.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 322.3ms\n",
      "Speed: 4.5ms preprocess, 322.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 303.2ms\n",
      "Speed: 2.9ms preprocess, 303.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 281.4ms\n",
      "Speed: 2.1ms preprocess, 281.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 294.7ms\n",
      "Speed: 2.1ms preprocess, 294.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 279.2ms\n",
      "Speed: 2.1ms preprocess, 279.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 empleado, 1 mostrador, 284.2ms\n",
      "Speed: 2.1ms preprocess, 284.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 289.2ms\n",
      "Speed: 2.6ms preprocess, 289.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 284.4ms\n",
      "Speed: 1.9ms preprocess, 284.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 271.5ms\n",
      "Speed: 2.1ms preprocess, 271.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 281.0ms\n",
      "Speed: 2.1ms preprocess, 281.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 empleado, 3 mostradors, 275.4ms\n",
      "Speed: 2.3ms preprocess, 275.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 empleado, 2 mostradors, 270.1ms\n",
      "Speed: 2.3ms preprocess, 270.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 empleado, 2 mostradors, 271.2ms\n",
      "Speed: 2.2ms preprocess, 271.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 empleado, 2 mostradors, 291.4ms\n",
      "Speed: 2.9ms preprocess, 291.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 empleado, 2 mostradors, 278.5ms\n",
      "Speed: 2.5ms preprocess, 278.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 2 mostradors, 286.3ms\n",
      "Speed: 2.0ms preprocess, 286.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 275.1ms\n",
      "Speed: 2.2ms preprocess, 275.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 2 mostradors, 275.3ms\n",
      "Speed: 2.4ms preprocess, 275.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 311.4ms\n",
      "Speed: 2.6ms preprocess, 311.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 268.2ms\n",
      "Speed: 2.2ms preprocess, 268.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 1 mostrador, 297.8ms\n",
      "Speed: 2.2ms preprocess, 297.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 1 mostrador, 309.1ms\n",
      "Speed: 2.1ms preprocess, 309.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 1 mostrador, 299.0ms\n",
      "Speed: 4.3ms preprocess, 299.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 281.3ms\n",
      "Speed: 2.9ms preprocess, 281.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 277.7ms\n",
      "Speed: 2.8ms preprocess, 277.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 288.7ms\n",
      "Speed: 2.1ms preprocess, 288.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 293.0ms\n",
      "Speed: 2.4ms preprocess, 293.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 mostrador, 275.7ms\n",
      "Speed: 2.1ms preprocess, 275.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 mostrador, 293.0ms\n",
      "Speed: 2.2ms preprocess, 293.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 mostrador, 277.5ms\n",
      "Speed: 2.6ms preprocess, 277.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 mostrador, 280.9ms\n",
      "Speed: 2.3ms preprocess, 280.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 289.4ms\n",
      "Speed: 2.5ms preprocess, 289.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 283.0ms\n",
      "Speed: 2.6ms preprocess, 283.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 295.0ms\n",
      "Speed: 2.3ms preprocess, 295.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 318.8ms\n",
      "Speed: 4.9ms preprocess, 318.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 1 empleado, 1 mostrador, 317.9ms\n",
      "Speed: 3.2ms preprocess, 317.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 1 empleado, 1 mostrador, 293.8ms\n",
      "Speed: 2.9ms preprocess, 293.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 mostrador, 270.1ms\n",
      "Speed: 2.1ms preprocess, 270.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 mostrador, 287.3ms\n",
      "Speed: 2.2ms preprocess, 287.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 mostrador, 296.6ms\n",
      "Speed: 3.4ms preprocess, 296.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 1 mostrador, 277.4ms\n",
      "Speed: 3.7ms preprocess, 277.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 mostrador, 286.3ms\n",
      "Speed: 3.4ms preprocess, 286.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 mostrador, 280.5ms\n",
      "Speed: 2.1ms preprocess, 280.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 empleado, 1 mostrador, 283.6ms\n",
      "Speed: 2.8ms preprocess, 283.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 empleado, 1 mostrador, 280.2ms\n",
      "Speed: 2.3ms preprocess, 280.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 mostrador, 277.0ms\n",
      "Speed: 3.3ms preprocess, 277.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 3 mostradors, 285.4ms\n",
      "Speed: 3.0ms preprocess, 285.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 2 mostradors, 275.3ms\n",
      "Speed: 2.1ms preprocess, 275.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 2 mostradors, 270.9ms\n",
      "Speed: 2.2ms preprocess, 270.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 2 mostradors, 304.6ms\n",
      "Speed: 2.3ms preprocess, 304.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 2 mostradors, 272.7ms\n",
      "Speed: 2.0ms preprocess, 272.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 3 mostradors, 277.7ms\n",
      "Speed: 2.1ms preprocess, 277.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 3 mostradors, 270.9ms\n",
      "Speed: 2.1ms preprocess, 270.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 3 mostradors, 291.7ms\n",
      "Speed: 2.2ms preprocess, 291.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 3 mostradors, 269.6ms\n",
      "Speed: 3.1ms preprocess, 269.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 clientes, 2 mostradors, 285.2ms\n",
      "Speed: 2.1ms preprocess, 285.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 2 mostradors, 279.4ms\n",
      "Speed: 2.6ms preprocess, 279.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 275.0ms\n",
      "Speed: 2.2ms preprocess, 275.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 273.6ms\n",
      "Speed: 2.6ms preprocess, 273.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 280.8ms\n",
      "Speed: 2.1ms preprocess, 280.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 2 mostradors, 298.9ms\n",
      "Speed: 4.8ms preprocess, 298.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 333.2ms\n",
      "Speed: 3.9ms preprocess, 333.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 277.1ms\n",
      "Speed: 2.5ms preprocess, 277.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 301.1ms\n",
      "Speed: 2.5ms preprocess, 301.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 276.8ms\n",
      "Speed: 2.1ms preprocess, 276.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 mostrador, 293.7ms\n",
      "Speed: 2.8ms preprocess, 293.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 2 mostradors, 294.8ms\n",
      "Speed: 2.2ms preprocess, 294.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 285.0ms\n",
      "Speed: 3.2ms preprocess, 285.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 274.2ms\n",
      "Speed: 2.1ms preprocess, 274.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 279.5ms\n",
      "Speed: 2.1ms preprocess, 279.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 clientes, 1 empleado, 273.5ms\n",
      "Speed: 2.2ms preprocess, 273.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 283.9ms\n",
      "Speed: 4.2ms preprocess, 283.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 274.7ms\n",
      "Speed: 2.2ms preprocess, 274.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 302.9ms\n",
      "Speed: 2.3ms preprocess, 302.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 277.0ms\n",
      "Speed: 2.2ms preprocess, 277.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 276.9ms\n",
      "Speed: 2.1ms preprocess, 276.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 290.8ms\n",
      "Speed: 2.3ms preprocess, 290.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 292.6ms\n",
      "Speed: 3.2ms preprocess, 292.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 294.7ms\n",
      "Speed: 6.4ms preprocess, 294.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 296.0ms\n",
      "Speed: 2.3ms preprocess, 296.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 1 mostrador, 304.7ms\n",
      "Speed: 2.1ms preprocess, 304.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 1 mostrador, 286.4ms\n",
      "Speed: 2.5ms preprocess, 286.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 303.9ms\n",
      "Speed: 2.1ms preprocess, 303.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 1 mostrador, 297.6ms\n",
      "Speed: 4.2ms preprocess, 297.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 1 mostrador, 281.1ms\n",
      "Speed: 2.7ms preprocess, 281.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 271.7ms\n",
      "Speed: 2.2ms preprocess, 271.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 1 empleado, 1 mostrador, 369.6ms\n",
      "Speed: 2.4ms preprocess, 369.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 1 empleado, 2 mostradors, 280.4ms\n",
      "Speed: 2.4ms preprocess, 280.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 1 empleado, 2 mostradors, 268.2ms\n",
      "Speed: 2.2ms preprocess, 268.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 2 mostradors, 276.1ms\n",
      "Speed: 2.4ms preprocess, 276.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 303.0ms\n",
      "Speed: 2.2ms preprocess, 303.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 3 mostradors, 271.4ms\n",
      "Speed: 2.1ms preprocess, 271.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 2 mostradors, 295.9ms\n",
      "Speed: 2.0ms preprocess, 295.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 2 mostradors, 281.8ms\n",
      "Speed: 2.3ms preprocess, 281.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 2 mostradors, 272.0ms\n",
      "Speed: 2.5ms preprocess, 272.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 2 mostradors, 274.9ms\n",
      "Speed: 2.3ms preprocess, 274.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 2 mostradors, 279.3ms\n",
      "Speed: 2.2ms preprocess, 279.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 1 mostrador, 275.7ms\n",
      "Speed: 2.2ms preprocess, 275.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 1 mostrador, 260.2ms\n",
      "Speed: 2.1ms preprocess, 260.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 1 mostrador, 280.7ms\n",
      "Speed: 2.2ms preprocess, 280.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# crea un csv con la cantidad de clientes detectados en total y los que estan cerca de mostrador\n",
    "resultados_clientes_totales = []\n",
    "\n",
    "# Procesar cada fotograma\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Obtener el número de fotograma y calcular el tiempo en segundos\n",
    "    frame_number = int(video.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    segundos_transcurridos = frame_number / fps\n",
    "\n",
    "    # Calcular la nueva fecha y hora\n",
    "    nueva_fecha_hora = fecha_hora_inicial + timedelta(seconds=segundos_transcurridos)\n",
    "    fecha_hora_exacta = nueva_fecha_hora.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Realizar la detección de objetos (clientes y empleados)\n",
    "    resultados_deteccion = model(frame)\n",
    "\n",
    "    # Extraer las detecciones\n",
    "    detecciones = resultados_deteccion[0].boxes if resultados_deteccion else []\n",
    "\n",
    "    # Contar clientes cerca del mostrador y obtener sus coordenadas\n",
    "    clientes_mostrador, clientes_detectados = contar_clientes_linea(detecciones, x1_mostrador, y1_mostrador, x2_mostrador, y2_mostrador)\n",
    "\n",
    "    # Contar todos los clientes detectados en el fotograma\n",
    "    clientes_totales = sum(1 for deteccion in detecciones if int(deteccion.cls[0].item()) == 1)  # Suponiendo que 1 es la clase \"cliente\"\n",
    "\n",
    "    # Guardar la información del primer cliente detectado (si hay alguno)\n",
    "    if clientes_detectados:\n",
    "        x_cliente, y_cliente = clientes_detectados[0]  # Tomar la primera detección\n",
    "\n",
    "        # Guardar la detección en la lista de resultados\n",
    "        resultados_clientes_totales.append([fecha_hora_exacta, clientes_mostrador, clientes_totales, x_cliente, y_cliente])\n",
    "\n",
    "# Guardar los resultados de detección con clientes totales en un CSV\n",
    "df_clientes_totales = pd.DataFrame(resultados_clientes_totales, columns=['Fecha Hora y Segundo', 'Clientes Cerca del Mostrador', 'Clientes Totales', 'X Cliente', 'Y Cliente'])\n",
    "df_clientes_totales.to_csv('resultados_clientes_totales.csv', index=False)\n",
    "\n",
    "# Liberar el video y cerrar ventanas\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Cargar el video\n",
    "video = cv2.VideoCapture(\"C:\\\\Users\\\\alvar\\\\Desktop\\\\Proyecto G3\\\\ProyectoGrupal-G3-UEM\\\\grabaciones\\\\grabacion_2025-02-21_19-42-20.mp4\")\n",
    "\n",
    "# Saltar los primeros 4 frames para llegar al quinto\n",
    "frame_count = 0\n",
    "while frame_count < 100:\n",
    "    ret, frame = video.read()\n",
    "    frame_count += 1\n",
    "    if not ret:\n",
    "        print(\"No se pudo leer el frame 5.\")\n",
    "        video.release()\n",
    "        exit()\n",
    "\n",
    "# Definir la coordenada del objeto detectado (según el CSV)\n",
    "x, y = 436.643310546875,313.2765808105469 # Centro de la caja\n",
    "\n",
    "# Dibujar el punto del objeto detectado\n",
    "cv2.circle(frame, (int(x), int(y)), 5, (255, 0, 0), -1)  # Azul\n",
    "\n",
    "# Dibujar la línea del mostrador\n",
    "cv2.line(frame, (x1_mostrador, y1_mostrador), (x2_mostrador, y2_mostrador), (0, 0, 255), 2)  # Rojo\n",
    "\n",
    "# Mostrar el frame\n",
    "cv2.imshow(\"Detección\", frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Liberar el video\n",
    "video.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
