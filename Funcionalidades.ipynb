{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcionalidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo YOLO11s fine-tuned\n",
    "model = YOLO('C:\\\\Users\\\\alvar\\\\Desktop\\\\Proyecto G3\\\\ProyectoGrupal-G3-UEM\\\\modelos\\\\best.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cantidad de clientes por zona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordenadas: (476, 251)\n",
      "Coordenadas: (787, 562)\n"
     ]
    }
   ],
   "source": [
    "# Funcion para determinar coordenadas de objetos en videos\n",
    "import cv2\n",
    "\n",
    "# Función de callback para obtener coordenadas al hacer clic\n",
    "def obtener_coordenadas(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:  # Solo muestra al hacer clic izquierdo\n",
    "        print(f'Coordenadas: ({x}, {y})')\n",
    "\n",
    "# Capturar un frame del video\n",
    "cap = cv2.VideoCapture('C:\\\\Users\\\\alvar\\\\Desktop\\\\Proyecto G3\\\\ProyectoGrupal-G3-UEM\\\\videos camaras seleccionadas\\\\Canal2.mp4')\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if ret:\n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.setMouseCallback('Frame', obtener_coordenadas)  # Asigna la función al frame\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No se pudo leer el frame del video.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular la distancia entre un punto (px, py) y una línea definida por dos puntos (x1, y1) y (x2, y2)\n",
    "def distancia_punto_linea(px, py, x1, y1, x2, y2):\n",
    "    return abs((y2 - y1) * px - (x2 - x1) * py + x2 * y1 - y2 * x1) / np.sqrt((y2 - y1)**2 + (x2 - x1)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las coordenadas de la línea del mostrador (inicio y fin)\n",
    "x1_mostrador, y1_mostrador = 476, 251\n",
    "x2_mostrador, y2_mostrador = 787, 562"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para contar los clientes cerca de la línea del mostrador\n",
    "def contar_clientes_linea(detecciones, x1_mostrador, y1_mostrador, x2_mostrador, y2_mostrador):\n",
    "    count = 0\n",
    "    for deteccion in detecciones:\n",
    "        # Extraer las coordenadas (xywh) y la confianza\n",
    "        bbox = deteccion.xywh[0]  # xywh de la detección\n",
    "        x, y, w, h = bbox[0], bbox[1], bbox[2], bbox[3]  # Extraemos las coordenadas y el tamaño\n",
    "        \n",
    "        # Calcular el centro del objeto (usamos las coordenadas en formato xywh)\n",
    "        centro_x, centro_y = x + w / 2, y - h / 2  # Centro del objeto\n",
    "\n",
    "        # Calcular la distancia entre el centro del objeto y la línea del mostrador\n",
    "        distancia = distancia_punto_linea(centro_x, centro_y, x1_mostrador, y1_mostrador, x2_mostrador, y2_mostrador)\n",
    "\n",
    "        # Si la distancia es pequeña, consideramos que el cliente está en la zona del mostrador\n",
    "        if distancia < 50:  # Ajusta el umbral según sea necesario\n",
    "            count += 1\n",
    "\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m video \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124malvar\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mProyecto G3\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mProyectoGrupal-G3-UEM\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mvideos camaras seleccionadas\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCanal2.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mvideo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#  funcion para ver la Linea que define al mostrador: \n",
    "video = cv2.VideoCapture(\"C:\\\\Users\\\\alvar\\\\Desktop\\\\Proyecto G3\\\\ProyectoGrupal-G3-UEM\\\\videos camaras seleccionadas\\\\Canal2.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Pintar la línea en el frame\n",
    "    color = (0, 255, 0)  # Color de la línea (verde en este caso)\n",
    "    grosor = 2  # Grosor de la línea\n",
    "    cv2.line(frame, (x1_mostrador, y1_mostrador), (x2_mostrador, y2_mostrador), color, grosor)\n",
    "\n",
    "    # Mostrar el frame con la línea\n",
    "    cv2.imshow('Frame con Linea Mostrador', frame)\n",
    "\n",
    "    # Salir si se presiona la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar el video y cerrar la ventana\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer video\n",
    "import cv2\n",
    "video = cv2.VideoCapture(\"C:\\\\Users\\\\alvar\\\\Desktop\\\\Proyecto G3\\\\ProyectoGrupal-G3-UEM\\\\grabaciones\\\\grabacion_2025-02-21_19-42-20.mp4\")\n",
    "\n",
    "# Lista para almacenar los resultados\n",
    "resultados = []\n",
    "\n",
    "# Extraer la fecha y hora inicial desde el nombre del archivo\n",
    "nombre_video = \"grabacion_2025-02-21_19-42-20.mp4\"\n",
    "fecha_hora_inicial_str = nombre_video.split('_')[1] + \" \" + nombre_video.split('_')[2].replace('.mp4', '')\n",
    "fecha_hora_inicial = datetime.strptime(fecha_hora_inicial_str, \"%Y-%m-%d %H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 447.5ms\n",
      "Speed: 7.6ms preprocess, 447.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 388.0ms\n",
      "Speed: 5.1ms preprocess, 388.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 443.3ms\n",
      "Speed: 2.7ms preprocess, 443.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 413.7ms\n",
      "Speed: 3.2ms preprocess, 413.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 367.5ms\n",
      "Speed: 2.3ms preprocess, 367.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 318.9ms\n",
      "Speed: 2.9ms preprocess, 318.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 288.1ms\n",
      "Speed: 2.1ms preprocess, 288.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 278.8ms\n",
      "Speed: 2.1ms preprocess, 278.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 329.5ms\n",
      "Speed: 2.2ms preprocess, 329.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 333.3ms\n",
      "Speed: 2.6ms preprocess, 333.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 305.1ms\n",
      "Speed: 3.6ms preprocess, 305.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 333.3ms\n",
      "Speed: 2.8ms preprocess, 333.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 413.2ms\n",
      "Speed: 3.1ms preprocess, 413.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 392.2ms\n",
      "Speed: 4.8ms preprocess, 392.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 empleado, 1 mostrador, 350.4ms\n",
      "Speed: 2.3ms preprocess, 350.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 334.9ms\n",
      "Speed: 2.3ms preprocess, 334.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 428.6ms\n",
      "Speed: 10.5ms preprocess, 428.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 368.4ms\n",
      "Speed: 6.2ms preprocess, 368.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 358.1ms\n",
      "Speed: 2.2ms preprocess, 358.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 empleado, 3 mostradors, 317.4ms\n",
      "Speed: 2.8ms preprocess, 317.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 empleado, 2 mostradors, 354.2ms\n",
      "Speed: 2.2ms preprocess, 354.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 empleado, 2 mostradors, 376.0ms\n",
      "Speed: 2.7ms preprocess, 376.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 empleado, 2 mostradors, 327.7ms\n",
      "Speed: 2.6ms preprocess, 327.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 empleado, 2 mostradors, 283.5ms\n",
      "Speed: 2.4ms preprocess, 283.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 2 mostradors, 288.3ms\n",
      "Speed: 2.0ms preprocess, 288.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 273.8ms\n",
      "Speed: 2.1ms preprocess, 273.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 2 mostradors, 291.7ms\n",
      "Speed: 2.4ms preprocess, 291.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 290.1ms\n",
      "Speed: 2.3ms preprocess, 290.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 286.1ms\n",
      "Speed: 3.5ms preprocess, 286.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 1 mostrador, 286.7ms\n",
      "Speed: 2.0ms preprocess, 286.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 1 mostrador, 285.5ms\n",
      "Speed: 2.5ms preprocess, 285.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 1 mostrador, 556.1ms\n",
      "Speed: 2.3ms preprocess, 556.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 351.7ms\n",
      "Speed: 4.1ms preprocess, 351.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 351.0ms\n",
      "Speed: 3.3ms preprocess, 351.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 343.6ms\n",
      "Speed: 2.9ms preprocess, 343.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 1 mostrador, 305.9ms\n",
      "Speed: 4.5ms preprocess, 305.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 mostrador, 290.6ms\n",
      "Speed: 2.4ms preprocess, 290.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 mostrador, 274.0ms\n",
      "Speed: 2.3ms preprocess, 274.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 mostrador, 280.5ms\n",
      "Speed: 2.3ms preprocess, 280.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 mostrador, 290.8ms\n",
      "Speed: 2.1ms preprocess, 290.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 306.2ms\n",
      "Speed: 2.0ms preprocess, 306.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 401.9ms\n",
      "Speed: 3.4ms preprocess, 401.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 322.6ms\n",
      "Speed: 2.4ms preprocess, 322.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 286.0ms\n",
      "Speed: 2.1ms preprocess, 286.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 1 empleado, 1 mostrador, 278.0ms\n",
      "Speed: 2.3ms preprocess, 278.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 1 empleado, 1 mostrador, 308.4ms\n",
      "Speed: 2.3ms preprocess, 308.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 mostrador, 317.8ms\n",
      "Speed: 2.9ms preprocess, 317.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 mostrador, 320.8ms\n",
      "Speed: 3.1ms preprocess, 320.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 mostrador, 331.5ms\n",
      "Speed: 2.2ms preprocess, 331.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 1 mostrador, 346.5ms\n",
      "Speed: 3.9ms preprocess, 346.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 mostrador, 288.0ms\n",
      "Speed: 3.7ms preprocess, 288.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 mostrador, 294.6ms\n",
      "Speed: 2.2ms preprocess, 294.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 empleado, 1 mostrador, 284.1ms\n",
      "Speed: 2.1ms preprocess, 284.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 empleado, 1 mostrador, 266.6ms\n",
      "Speed: 2.3ms preprocess, 266.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 1 mostrador, 286.1ms\n",
      "Speed: 2.2ms preprocess, 286.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 clientes, 3 mostradors, 275.2ms\n",
      "Speed: 2.2ms preprocess, 275.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 2 mostradors, 287.7ms\n",
      "Speed: 2.2ms preprocess, 287.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 2 mostradors, 294.1ms\n",
      "Speed: 2.5ms preprocess, 294.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 2 mostradors, 289.2ms\n",
      "Speed: 3.1ms preprocess, 289.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 2 mostradors, 289.1ms\n",
      "Speed: 2.7ms preprocess, 289.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 3 mostradors, 293.1ms\n",
      "Speed: 2.2ms preprocess, 293.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 3 mostradors, 287.3ms\n",
      "Speed: 2.1ms preprocess, 287.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 3 mostradors, 273.9ms\n",
      "Speed: 3.2ms preprocess, 273.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 clientes, 3 mostradors, 282.1ms\n",
      "Speed: 2.5ms preprocess, 282.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 clientes, 2 mostradors, 288.5ms\n",
      "Speed: 2.3ms preprocess, 288.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 2 mostradors, 286.4ms\n",
      "Speed: 3.6ms preprocess, 286.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 268.7ms\n",
      "Speed: 2.2ms preprocess, 268.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 274.7ms\n",
      "Speed: 2.3ms preprocess, 274.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 274.5ms\n",
      "Speed: 2.1ms preprocess, 274.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 2 mostradors, 277.0ms\n",
      "Speed: 3.5ms preprocess, 277.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 278.7ms\n",
      "Speed: 3.2ms preprocess, 278.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 289.8ms\n",
      "Speed: 2.4ms preprocess, 289.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 288.1ms\n",
      "Speed: 2.1ms preprocess, 288.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 1 mostrador, 318.0ms\n",
      "Speed: 2.1ms preprocess, 318.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 mostrador, 332.9ms\n",
      "Speed: 2.5ms preprocess, 332.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 2 mostradors, 286.3ms\n",
      "Speed: 3.2ms preprocess, 286.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 295.6ms\n",
      "Speed: 2.1ms preprocess, 295.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 301.3ms\n",
      "Speed: 2.0ms preprocess, 301.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 1 mostrador, 347.9ms\n",
      "Speed: 2.1ms preprocess, 347.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 clientes, 1 empleado, 330.2ms\n",
      "Speed: 2.5ms preprocess, 330.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 437.9ms\n",
      "Speed: 2.1ms preprocess, 437.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 clientes, 1 empleado, 303.2ms\n",
      "Speed: 2.4ms preprocess, 303.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 284.0ms\n",
      "Speed: 2.1ms preprocess, 284.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 clientes, 1 empleado, 284.1ms\n",
      "Speed: 2.8ms preprocess, 284.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 312.7ms\n",
      "Speed: 2.5ms preprocess, 312.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 296.3ms\n",
      "Speed: 2.4ms preprocess, 296.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 289.0ms\n",
      "Speed: 2.0ms preprocess, 289.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 284.7ms\n",
      "Speed: 2.3ms preprocess, 284.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 287.7ms\n",
      "Speed: 2.6ms preprocess, 287.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 1 mostrador, 291.6ms\n",
      "Speed: 3.6ms preprocess, 291.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 1 mostrador, 306.6ms\n",
      "Speed: 7.4ms preprocess, 306.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 284.9ms\n",
      "Speed: 2.2ms preprocess, 284.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 1 mostrador, 279.3ms\n",
      "Speed: 2.9ms preprocess, 279.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 1 mostrador, 285.1ms\n",
      "Speed: 2.1ms preprocess, 285.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 291.5ms\n",
      "Speed: 2.3ms preprocess, 291.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 5 clientes, 1 empleado, 1 mostrador, 292.7ms\n",
      "Speed: 2.2ms preprocess, 292.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 1 empleado, 2 mostradors, 297.7ms\n",
      "Speed: 2.6ms preprocess, 297.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 1 empleado, 2 mostradors, 296.0ms\n",
      "Speed: 2.6ms preprocess, 296.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 6 clientes, 2 mostradors, 338.3ms\n",
      "Speed: 2.3ms preprocess, 338.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 1 mostrador, 358.2ms\n",
      "Speed: 2.2ms preprocess, 358.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 3 mostradors, 341.4ms\n",
      "Speed: 2.7ms preprocess, 341.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 3 clientes, 2 mostradors, 289.9ms\n",
      "Speed: 4.6ms preprocess, 289.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 2 mostradors, 396.1ms\n",
      "Speed: 2.2ms preprocess, 396.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 2 mostradors, 367.0ms\n",
      "Speed: 2.4ms preprocess, 367.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 4 clientes, 2 mostradors, 363.5ms\n",
      "Speed: 3.3ms preprocess, 363.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 2 mostradors, 301.7ms\n",
      "Speed: 2.3ms preprocess, 301.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 1 mostrador, 276.7ms\n",
      "Speed: 3.7ms preprocess, 276.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 1 mostrador, 286.0ms\n",
      "Speed: 3.4ms preprocess, 286.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 caja, 2 clientes, 1 mostrador, 325.4ms\n",
      "Speed: 2.3ms preprocess, 325.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Obtener el número de fotograma y calcular el tiempo en segundos\n",
    "    frame_number = int(video.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    segundos_transcurridos = frame_number / fps\n",
    "\n",
    "    # Calcular la nueva fecha y hora basándonos en la fecha de inicio\n",
    "    nueva_fecha_hora = fecha_hora_inicial + timedelta(seconds=segundos_transcurridos)\n",
    "\n",
    "    # Formatear la nueva fecha y hora\n",
    "    fecha_hora_exacta = nueva_fecha_hora.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Realizar la detección de objetos (clientes y empleados) usando el modelo YOLOv11s\n",
    "    resultados_deteccion = model(frame)  # Detecta los objetos en el fotograma\n",
    "\n",
    "    # Extraer las detecciones de los objetos\n",
    "    detecciones = resultados_deteccion[0].boxes  # Obtenemos las cajas de las detecciones\n",
    "\n",
    "    # Contar clientes cerca de la línea del mostrador\n",
    "    clientes_mostrador = contar_clientes_linea(detecciones, x1_mostrador, y1_mostrador, x2_mostrador, y2_mostrador)\n",
    "\n",
    "    # Guardar los resultados en la lista\n",
    "    resultados.append([fecha_hora_exacta, segundos_transcurridos, clientes_mostrador])\n",
    "\n",
    "# Guardar los resultados en un archivo CSV\n",
    "df = pd.DataFrame(resultados, columns=['Fecha Hora', 'Segundo', 'Clientes Zona Mostrador'])\n",
    "df.to_csv('resultados_deteccion_mostrador.csv', index=False)\n",
    "\n",
    "# Liberar el video y cerrar la ventana\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
